{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "include '/Users/allanjie/Documents/workspace/statnlp-ner/nn-crf-interface/neural_server/SeqBRNNGRU.lua'\n",
    "torch.manualSeed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingSize = 3\n",
    "vocabSize = 5\n",
    "numSents = 2\n",
    "numWords = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = nn.LookupTableMaskZero(vocabSize, embeddingSize)\n",
    "function buildBiGRU(inputSize, outputSize, dropout, tanhGRU)\n",
    "    local bigru = nn.Sequential():add(nn.Transpose({1,2})):add(nn.SplitTable(1))\n",
    "    local fwdSeq = nn.Sequencer(nn.GRU(inputSize, outputSize, 9999, dropout):maskZero(1))\n",
    "    local bwdSeq = nn.Sequential():add(nn.ReverseTable())\n",
    "    bwdSeq:add(nn.Sequencer(nn.GRU(inputSize, outputSize, 9999, dropout):maskZero(1)))\n",
    "    bwdSeq:add(nn.ReverseTable())\n",
    "    local biconcat = nn.ConcatTable():add(fwdSeq):add(bwdSeq)\n",
    "    bigru:add(biconcat):add(nn.ZipTable()):add(nn.Sequencer(nn.JoinTable(1,1)))\n",
    "    local mapTable = nn.MapTable()\n",
    "    local combineSize\n",
    "    if tanhGRU then\n",
    "        local mapOp = nn.Sequential()\n",
    "        mapOp:add(nn.Linear(2 * outputSize, outputSize)):add(nn.Tanh())\n",
    "        mapOp:add(nn.Unsqueeze(1))\n",
    "        mapTable:add(mapOp)\n",
    "        combineSize = outputSize\n",
    "    else\n",
    "        mapTable:add(nn.Unsqueeze(1))\n",
    "        combineSize = 2 * outputSize\n",
    "    end\n",
    "    bigru:add(mapTable):add(nn.JoinTable(1)):add(nn.Transpose({1,2}))\n",
    "    return bigru\n",
    "end\n",
    "\n",
    "brnn = nn.SeqBRNNGRU(embeddingSize, embeddingSize, true, nn.JoinTable(3))\n",
    "brgru = buildBiGRU(embeddingSize, embeddingSize, 0.0, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2  1  4\n",
       " 3  2  0\n",
       "[torch.IntTensor of size 2x3]\n",
       "\n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.IntTensor(numSents,numWords)\n",
    "input[1][1] = 2\n",
    "input[1][2] = 1\n",
    "input[1][3] = 4\n",
    "input[2][1] = 3\n",
    "input[2][2] = 2\n",
    "input[2][3] = 0\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       "  0.2241 -0.0318 -0.3360\n",
       "  0.0161 -0.0836 -0.3217\n",
       " -0.2200 -0.1084 -0.3217\n",
       "\n",
       "(2,.,.) = \n",
       "  0.2043 -0.0514 -0.4028\n",
       "  0.1308  0.0018 -0.3930\n",
       " -0.1242 -0.1052 -0.3834\n",
       "[torch.DoubleTensor of size 2x3x3]\n",
       "\n"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylt = lt:forward(input)\n",
    "-- print(ylt)\n",
    "-- ybrnn = \n",
    "ybrnn = brgru:forward(ylt)\n",
    "print(ybrnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
