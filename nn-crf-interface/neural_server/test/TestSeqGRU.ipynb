{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'rnn'\n",
    "include '/Users/allanjie/Documents/workspace/statnlp-ner/nn-crf-interface/neural_server/SeqBRNNGRU.lua'\n",
    "torch.manualSeed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingSize = 3\n",
    "vocabSize = 5\n",
    "numSents = 2\n",
    "numWords = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lt = nn.LookupTableMaskZero(vocabSize, embeddingSize)\n",
    "function buildBiGRU(inputSize, outputSize, dropout, tanhGRU)\n",
    "    local bigru = nn.Sequential():add(nn.Transpose({1,2})):add(nn.SplitTable(1))\n",
    "    local fwdSeq = nn.Sequencer(nn.GRU(inputSize, outputSize, 9999, dropout):maskZero(1))\n",
    "    local bwdSeq = nn.Sequential():add(nn.ReverseTable())\n",
    "    bwdSeq:add(nn.Sequencer(nn.GRU(inputSize, outputSize, 9999, dropout):maskZero(1)))\n",
    "    bwdSeq:add(nn.ReverseTable())\n",
    "    local biconcat = nn.ConcatTable():add(fwdSeq):add(bwdSeq)\n",
    "    bigru:add(biconcat):add(nn.ZipTable()):add(nn.Sequencer(nn.JoinTable(1,1)))\n",
    "    local mapTable = nn.MapTable()\n",
    "    local combineSize\n",
    "    if tanhGRU then\n",
    "        local mapOp = nn.Sequential()\n",
    "        mapOp:add(nn.Linear(2 * outputSize, outputSize)):add(nn.Tanh())\n",
    "        mapOp:add(nn.Unsqueeze(1))\n",
    "        mapTable:add(mapOp)\n",
    "        combineSize = outputSize\n",
    "    else\n",
    "        mapTable:add(nn.Unsqueeze(1))\n",
    "        combineSize = 2 * outputSize\n",
    "    end\n",
    "    bigru:add(mapTable):add(nn.JoinTable(1)):add(nn.Transpose({1,2}))\n",
    "    return bigru\n",
    "end\n",
    "\n",
    "brnn = nn.SeqBRNNGRU(embeddingSize, embeddingSize, true, nn.JoinTable(3))\n",
    "brgru = buildBiGRU(embeddingSize, embeddingSize, 0.0, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 2  1  4\n",
       " 3  2  0\n",
       "[torch.IntTensor of size 2x3]\n",
       "\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.IntTensor(numSents,numWords)\n",
    "input[1][1] = 2\n",
    "input[1][2] = 1\n",
    "input[1][3] = 4\n",
    "input[2][1] = 3\n",
    "input[2][2] = 2\n",
    "input[2][3] = 0\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,.,.) = \n",
       "  0.1555  0.0341  0.3510\n",
       " -0.0150  0.4438  0.0697\n",
       " -0.1099  0.5307  0.3147\n",
       "\n",
       "(2,.,.) = \n",
       "  0.0404  0.4041  0.3168\n",
       "  0.1408  0.0702  0.4273\n",
       "  0.0133  0.3636  0.1612\n",
       "[torch.DoubleTensor of size 2x3x3]\n",
       "\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylt = lt:forward(input)\n",
    "-- print(ylt)\n",
    "-- ybrnn = \n",
    "ybrnn = brgru:forward(ylt)\n",
    "print(ybrnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
